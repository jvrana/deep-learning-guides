{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGL Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000],\n",
       "        [ 0.1392,  1.3757],\n",
       "        [ 0.0146, -1.5229],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
    "g.ndata['x'] = torch.randn(5, 2)\n",
    "\n",
    "# we can send and receive messages using edge (u --> v)\n",
    "# we cannot send messages to edges that do not exist, however\n",
    "g.send_and_recv(([0, 1], [1, 2]), fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
    "g.ndata['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000],\n",
       "        [ 0.2271,  0.0784],\n",
       "        [-0.3758,  0.2759],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can send and receive messages using edge ids\n",
    "g.send_and_recv([0], fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
    "g.ndata['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[ 0.2903, -0.1730],\n",
      "        [ 0.1695, -0.0738],\n",
      "        [ 0.6497, -1.1092],\n",
      "        [ 0.6976, -0.7749],\n",
      "        [-0.6042,  0.7806]])}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# **local scope**\n",
    "# we can enter a local scope for a graph such that any mutations in the graph are not \n",
    "# reflected in the original graph\n",
    "g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
    "with g.local_scope():\n",
    "    g.ndata['x'] = torch.randn(5, 2)\n",
    "    print(g.ndata)\n",
    "print(g.ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': tensor([[-0.3580,  0.3352],\n",
      "        [-0.6294, -1.2133],\n",
      "        [ 2.5045,  0.4580],\n",
      "        [-0.1749,  0.9500],\n",
      "        [ 0.5554, -1.2297]]), 'q': tensor([[ 0.6454,  1.0083],\n",
      "        [-0.1463, -0.9820],\n",
      "        [-0.1117,  1.7270],\n",
      "        [ 1.0037,  2.5795],\n",
      "        [ 1.1025,  0.6385]]), 'v': tensor([[ 0.1606, -0.5321],\n",
      "        [ 0.9059, -1.0296],\n",
      "        [ 0.3193, -1.5199],\n",
      "        [ 1.0204,  0.5048],\n",
      "        [ 1.4193, -0.1029]]), 'wv': tensor([[  0.0000,   0.0000],\n",
      "        [  0.1320,  -0.4376],\n",
      "        [  0.2164,  -0.2459],\n",
      "        [  4.3543, -20.7302],\n",
      "        [  1.3672,   0.6764]]), 'z': tensor([[ 0.0000],\n",
      "        [ 0.8223],\n",
      "        [ 0.2388],\n",
      "        [13.6388],\n",
      "        [ 1.3399]])}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "message passaging using dgl resembles functional programming. We can make user-define function\n",
    "creation easier, by implementing a compose function\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "def compose(*funcs):\n",
    "    def composed(edges):\n",
    "        for _func in funcs:\n",
    "            _func(edges)\n",
    "    return composed\n",
    "\n",
    "g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
    "g.ndata['k'] = torch.randn(5, 2)\n",
    "g.ndata['q'] = torch.randn(5, 2)\n",
    "g.ndata['v'] = torch.randn(5, 2)\n",
    "\n",
    "\n",
    "def src_dot_dst(src_field, dst_field, out_field):\n",
    "    def func(edges):\n",
    "        return {out_field: (edges.src[src_field] * edges.dst[dst_field]).sum(-1, keepdim=True)}\n",
    "\n",
    "    return func\n",
    "\n",
    "def scaled_exp(field, scale_constant):\n",
    "    def func(edges):\n",
    "        # clamp for softmax numerical stability\n",
    "        return {field: th.exp((edges.data[field] / scale_constant).clamp(-5, 5))}\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "g.apply_edges(src_dot_dst('k', 'q', 'score'))\n",
    "g.apply_edges(scaled_exp('score', np.sqrt(2)))\n",
    "g.update_all(fn.u_mul_e('v', 'score', 'v'), fn.sum('v', 'wv'))\n",
    "g.update_all(fn.copy_edge('score', 'score'), fn.sum('score', 'z'))\n",
    "\n",
    "\n",
    "\n",
    "# # class Encoder(nn.Module):\n",
    "    \n",
    "# #     def __init__(self, layer: nn.Module, N: int):\n",
    "# #         super().__init__()\n",
    "# #         self.N = N\n",
    "# #         self.layers = clones(layer, N)\n",
    "# #         self.norm = nn.LayerNorm(layer.size)\n",
    "        \n",
    "# #     def \n",
    "\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "    \n",
    "# class Encoder(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "        \n",
    "# class Decoder(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
