{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch as th\n",
    "import dgl\n",
    "\n",
    "import dgl.function as fn\n",
    "\n",
    "g = dgl.graph(([0, 1, 2], [3, 4, 5]))\n",
    "g.ndata['h'] = th.randn((g.number_of_nodes(), 10))\n",
    "g.edata['w'] = th.randn((g.number_of_edges(), 1))\n",
    "\n",
    "g.update_all(fn.copy_u('h', 'm'), fn.sum('m', 'h_sum'))\n",
    "g.update_all(fn.u_mul_e('h', 'w', 'm'), fn.mean('m', 'h_max'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention layer of Transformer\n",
    "\n",
    "The **attention** layer, each node in module learns to assign weights on its incoming edges. For node pair $(i,j)$ with node $x_i,x_j \\in \\mathbb{R}^n$, the score of connection is as follows:\n",
    "\n",
    "$$\n",
    "q_j = W_q \\cdot x_j \\\\\n",
    "k_i = W_k \\cdot x_i \\\\\n",
    "v_i = W_v \\cdot x_i \\\\\n",
    "\\text{score} = q_j k_i\n",
    "$$\n",
    "\n",
    "$W_q, W_k, W_v \\in \\mathbb{R}^{n \\times d_k}$ map the representations of x to \"query\", \"key\", and \"value\" space repsectively. These values are three different linear projections of the data. For the \"query\" case ($W_j$), these are linear projections of source nodes for edges. For \"key\" and \"value\", were are linear projections of the destination nodes. The dot product between query source nodes and key destination nodes computes the score of the given connection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now walk through this procedure manually, and gradually move to the optimized dgl implementation. Another way to write is this procedure is\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax} ( \\frac{Q K^T}{\\sqrt{(d_k)}} ) V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4])\n",
      "torch.Size([10, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-04c711e75edb>:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention = torch.matmul(F.softmax(score), v)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import copy\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "d_k = 3\n",
    "x_j = torch.randn(10, d_k) # destination nodes j\n",
    "x_i = torch.randn(4, d_k)  # source nodes i\n",
    "W_q, W_k, W_v, W_o = clones(nn.Linear(3, 3), 4)\n",
    "q = W_q(x_j)\n",
    "k = W_k(x_i)\n",
    "v = W_v(x_i)\n",
    "score = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "print(score.shape)\n",
    "attention = torch.matmul(F.softmax(score), v)\n",
    "print(attention.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention\n",
    "\n",
    "For **multi-head attention**, we compute a portion of the attention and concatenate the results. Hence attention calculations can occur in parallel. Lets again walk through this manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4, 30])\n",
      "torch.Size([10, 5, 4, 3])\n",
      "tensor([[-0.3419, -2.0336, -1.3005],\n",
      "        [ 2.2123, -1.0456, -0.3535],\n",
      "        [ 1.0521,  3.1657,  1.2814],\n",
      "        [ 2.3995, -1.5056,  3.1917]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 30])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# say we have our three linear embeddings of query, key, and value\n",
    "# it is assumed the dimensions between key and value are equivalent\n",
    "q = torch.randn(10, 4, 30)\n",
    "k = torch.randn(10, 3, 30)\n",
    "v = torch.randn(10, 3, 30)\n",
    "\n",
    "# Attention is generally applied with QK^TV, often with scaling and softmax applied,\n",
    "# as in softmax(scaling * QK^T)V\n",
    "print(torch.matmul(torch.matmul(q, k.transpose(-2, -1)), v).shape)\n",
    "\n",
    "\n",
    "# to do multihead attention, we split the tensor across multiple heads\n",
    "# we first calculate some dimensions\n",
    "batch_size = q.size(0)\n",
    "d_model = q.size(-1)\n",
    "heads = 5\n",
    "d_k = d_model // heads\n",
    "\n",
    "# else we need to change our embeddings a bit\n",
    "assert d_model % heads == 0\n",
    "\n",
    "# then we split d_model across multiple heads\n",
    "q_view = q.view(batch_size, -1, heads, d_k)\n",
    "\n",
    "# we then swap the head to the non-matrix (i.e. batch) dimensions using transpose\n",
    "q_view = q_view.transpose(1, 2)\n",
    "\n",
    "# NOTE: it must be done in this was as not to juggle the values\n",
    "\n",
    "# resulting in (batch_size, h, i, d_k)\n",
    "# our aim is to sum across d_k during matrix multiplication, so that (b, h, i, d_k) * (b, h, d_k, j) -> (b, h, i, j)\n",
    "# final matmul with the value results in (b, h, i, j) * (b, h, j, d_k) -> (b, h, j, d_k)\n",
    "q_view = q.view(batch_size, -1, heads, d_k).transpose(1, 2)\n",
    "k_view = k.view(batch_size, -1, heads, d_k).transpose(1, 2)\n",
    "v_view = v.view(batch_size, -1, heads, d_k).transpose(1, 2)\n",
    "    \n",
    "z = torch.matmul(q_view, k_view.transpose(-2, -1))\n",
    "print(z.shape)\n",
    "\n",
    "# the attention as a specific head (e.g. batch=0, head=1) can be found using:\n",
    "print(z[0, 1])\n",
    "\n",
    "# out final values with attenion applied\n",
    "a = torch.matmul(z, v_view)\n",
    "\n",
    "# which returns us to the original shape\n",
    "a.view(batch_size, -1, heads * d_k).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Headed Attention and Graph Transformer\n",
    "\n",
    "We can quickly implement the initial embedding of the MultiHeadAttention. Right now, we are leaving out the more complicated forward propogation. We will walk through that implementation next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, h, dim_model):\n",
    "        super().__init__()\n",
    "        self.d_k = dim_model // h\n",
    "        assert dim_model % h == 0\n",
    "        self.h = h\n",
    "        # W_q, W_k, W_v, W_o\n",
    "        self.linears = clones(nn.Linear(dim_model, dim_model), 4)\n",
    "        \n",
    "    def get(self, x, fields='qkv'):\n",
    "        \"Return a dict of queries / keys / values.\"\n",
    "        batch_size = x.shape[0]\n",
    "        ret = {}\n",
    "        if 'q' in fields:\n",
    "            ret['q'] = self.linears[0](x).view(batch_size, self.h, self.d_k)\n",
    "        if 'k' in fields:\n",
    "            ret['k'] = self.linears[1](x).view(batch_size, self.h, self.d_k)\n",
    "        if 'v' in fields:\n",
    "            ret['v'] = self.linears[2](x).view(batch_size, self.h, self.d_k)\n",
    "        return ret\n",
    "    \n",
    "    def get_output(self, x):\n",
    "        \"get output of the multi-head attention\"\n",
    "        batch_size = x.shape[0]\n",
    "        return self.linears[3](x.view(batch_size, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will walk through the forward propogation using dgl. First, lets create a simple test graph and attach some data to the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=5, num_edges=4,\n",
      "      ndata_schemes={'q': Scheme(shape=(8,), dtype=torch.float32), 'k': Scheme(shape=(8,), dtype=torch.float32), 'v': Scheme(shape=(8,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dgl\n",
    "import dgl.function as fn # contains all the built-in optimized message passing and reduce functions.\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "\n",
    "g = dgl.graph(([0, 1, 2, 3], [2, 2, 3, 4]))\n",
    "x = torch.randn(g.number_of_nodes(), 8)\n",
    "# attn = MultiHeadAttention(2, 8)\n",
    "# ret = attn.get(x)\n",
    "g.ndata['q'] = torch.randn_like(x)\n",
    "g.ndata['k'] = torch.randn_like(x)\n",
    "g.ndata['v'] = torch.randn_like(x)\n",
    "\n",
    "nxg = nx.DiGraph(g.to_networkx())\n",
    "print(g)\n",
    "nx.draw(nxg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5014, -1.8072])\n",
      "(tensor([0, 1, 2, 3]), tensor([2, 2, 3, 4]))\n",
      "tensor([[ 0.5014, -1.8072]])\n"
     ]
    }
   ],
   "source": [
    "print(g.edges())\n",
    "\n",
    "g.apply_edges(fn.v_mul_u('q', 'k', 'score'))\n",
    "score = g.edata['score']\n",
    "print(score[:2].sum(1))\n",
    "\n",
    "# manually\n",
    "q = g.ndata['q'][2:3]\n",
    "k = g.ndata['k'][:2]\n",
    "v = g.ndata['v'][:2]\n",
    "\n",
    "mm = torch.matmul\n",
    "print(mm(q, k.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5014],\n",
      "        [-1.8072],\n",
      "        [ 4.4656],\n",
      "        [-2.3138]])\n"
     ]
    }
   ],
   "source": [
    "# now we create a user defined function\n",
    "\n",
    "def src_dot_dst(src_field, dst_field, out_field):\n",
    "    def func(edges):\n",
    "        return {out_field: (edges.src[src_field] * edges.dst[dst_field]).sum(-1, keepdim=True)}\n",
    "    return func\n",
    "\n",
    "def scaled_exp(field, scale_con)\n",
    "\n",
    "g.apply_edges(src_dot_dst('k', 'q', 'score'))\n",
    "print(g.edata['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7899, -4.7639,  0.0459,  0.1546,  0.6173, -0.0286, -0.3896,  2.2687],\n",
      "        [ 0.0890, -0.3561,  2.0339,  0.5506,  0.2999,  2.5642, -0.3474, -0.3684],\n",
      "        [-0.1353,  0.5503, -0.8651, -0.3484, -1.1232, -0.0104,  0.7730, -1.1547]])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7899, -4.7639,  0.0459,  0.1546,  0.6173, -0.0286, -0.3896,  2.2687],\n",
      "        [ 0.0890, -0.3561,  2.0339,  0.5506,  0.2999,  2.5642, -0.3474, -0.3684]])\n"
     ]
    }
   ],
   "source": [
    "g.update_all(fn.v_mul_u('q', 'k', 'score'), fn.sum('score', 'z'))\n",
    "g.update_all(fn.copy_u('z', 's'), fn.sum('s', 's'))\n",
    "print(g.ndata['z'])\n",
    "print(g.ndata['s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "o = W_o \\cdot \\text{concat} ([wv^{(0)},wv^{(1)},...,wv^{(h)}])\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, h, d_model):\n",
    "        super().__init__()\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        \n",
    "        # W_q, W_k, W_v, W_o\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
